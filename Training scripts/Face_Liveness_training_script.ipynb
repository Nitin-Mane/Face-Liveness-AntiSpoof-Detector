{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Liveness_Training_script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlWGZ6JobUDU"
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "%matplotlib inline\n",
        "%reload_ext tensorboard\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, f1_score, auc\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "import PIL\n",
        "\n",
        "def show_batch(data_loader, n=8):\n",
        "    for images, labels in data_loader:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images[:8], nrow=4).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "def get_num_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL6N9rHebs-G"
      },
      "source": [
        "DATASET = 'Facespoof_test'\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_ROUTING = 3\n",
        "LR_DECAY = 0.96\n",
        "LR_UPDATE_INTERVAL_IN_ITERATIONS = None # initialized later to every epoch, if value is None\n",
        "MODEL_SAVE_INTERVAL_IN_EPOCHS = 1\n",
        "\n",
        "NUM_WORKERS = 1\n",
        "LOG_INTERVAL = 100\n",
        "IMG_RECONSTRUCTION_INTERVAL = 500\n",
        "SEED = 1\n",
        "GPU_DEVICE = 0\n",
        "MULTI_GPU = False\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "DATA_PATH = 'logs/'\n",
        "G_DRIVE_DIR_BASE = '/content/drive/My Drive/Colab/Facespoof/Runs/'\n",
        "MODEL_DIR_BASE = DATA_PATH + 'models/'\n",
        "TB_RUN_DIR_BASE = DATA_PATH + 'runs/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y0t9baYeho1"
      },
      "source": [
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "if DATASET == 'Facespoof_test':\n",
        "    !unzip -qq '/content/drive/My Drive/Colab/Facespoof/Data/spoof_dummy.zip'\n",
        "    BATCH_SIZE = 8\n",
        "    TRAIN_VAL_RATIO = 0.8\n",
        "    train_val_data_path = '/content/spoof_dummy/train'\n",
        "    test_data_path = '/content/spoof_dummy/validation'\n",
        "    classes = ['fake', 'real']\n",
        "\n",
        "    common_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.26), (0.65,))\n",
        "    ])\n",
        "\n",
        "    train_val_transforms = transforms.Compose([\n",
        "        transforms.RandomAffine(degrees=(-5,5), translate=None, scale=(0.9, 1.2), shear=0, resample=False, fillcolor=0),\n",
        "        common_transforms\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        common_transforms\n",
        "    ])\n",
        "\n",
        "elif DATASET.upper() == 'Facespoof_low_res':\n",
        "    !unzip -qq '/content/drive/My Drive/Colab/Facespoof/Data/spoof.zip'\n",
        "    BATCH_SIZE = 8\n",
        "    TRAIN_VAL_RATIO = 0.8\n",
        "    train_val_data_path = '/content/spoof/train'\n",
        "    test_data_path = '/content/spoof/validation'\n",
        "    classes = ['fake', 'real']\n",
        "\n",
        "    common_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.26), (0.65,))\n",
        "    ])\n",
        "\n",
        "    train_val_transforms = transforms.Compose([\n",
        "        transforms.RandomAffine(degrees=(-5,5), translate=None, scale=(0.9, 1.2), shear=0, resample=False, fillcolor=0),\n",
        "        common_transforms\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        common_transforms\n",
        "    ])\n",
        "elif DATASET.upper() == 'Facespoof_high_res':\n",
        "    !unzip -qq '/content/drive/My Drive/Colab/Facespoof/Data/spoof2.zip'\n",
        "    BATCH_SIZE = 8\n",
        "    TRAIN_VAL_RATIO = 0.8\n",
        "    train_val_data_path = '/content/spoof2/train'\n",
        "    test_data_path = '/content/spoof2/validation'\n",
        "    classes = ['fake', 'real']\n",
        "\n",
        "    common_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.26), (0.65,))\n",
        "    ])\n",
        "\n",
        "    train_val_transforms = transforms.Compose([\n",
        "        transforms.RandomAffine(degrees=(-5,5), translate=None, scale=(0.9, 1.2), shear=0, resample=False, fillcolor=0),\n",
        "        common_transforms\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        common_transforms\n",
        "    ])\n",
        "else:\n",
        "    raise ValueError('DATASET not specified')\n",
        "\n",
        "TB_COMMENT = f'Network {DATASET} batch_size={BATCH_SIZE} lr={LEARNING_RATE} num_routing={NUM_ROUTING} lr_decay={LR_DECAY} E={EPOCHS}'\n",
        "TB_RUN_DIR = TB_RUN_DIR_BASE + TB_COMMENT\n",
        "MODEL_DIR = MODEL_DIR_BASE + TB_COMMENT\n",
        "G_DRIVE_DIR = G_DRIVE_DIR_BASE + TB_COMMENT\n",
        "print(TB_COMMENT)\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    !rm -r '/content/logs'\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    os.mkdir(DATA_PATH)\n",
        "\n",
        "if not os.path.exists(MODEL_DIR_BASE):\n",
        "    os.mkdir(MODEL_DIR_BASE)\n",
        "\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "if not os.path.exists(TB_RUN_DIR_BASE):\n",
        "    os.mkdir(TB_RUN_DIR_BASE)\n",
        "\n",
        "if not os.path.exists(TB_RUN_DIR):\n",
        "    os.mkdir(TB_RUN_DIR)\n",
        "\n",
        "if GPU_DEVICE is not None:\n",
        "    torch.cuda.set_device(GPU_DEVICE)\n",
        "\n",
        "if MULTI_GPU:\n",
        "    batch_size *= torch.cuda.device_count()\n",
        "\n",
        "loaders = {}\n",
        "train_val_set = torchvision.datasets.ImageFolder(root=train_val_data_path, transform = train_val_transforms)\n",
        "train_set_size = int(len(train_val_set)*TRAIN_VAL_RATIO)\n",
        "train_set, validation_set = random_split(train_val_set, [train_set_size, len(train_val_set) - train_set_size])\n",
        "loaders['train'] = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "loaders['validation'] = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "test_set = torchvision.datasets.ImageFolder(root=test_data_path, transform = test_transforms)\n",
        "loaders['test'] = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "print( 8*'#', f'Using {DATASET} dataset', 8*'#')\n",
        "print(\"Train loader. \\tSize: \", len(train_set), '\\tData Shape: ', train_set[0][0].shape, '\\tBatch len: ', len(loaders['train']))\n",
        "print(\"Val loader. \\tSize: \", len(validation_set), '\\tData Shape: ', validation_set[0][0].shape, '\\tBatch len: ', len(loaders['validation']))\n",
        "print(\"Test loader.  \\tSize: \", len(test_set), '\\tData Shape: ', test_set[0][0].shape, '\\tBatch len: ', len(loaders['test']))\n",
        "\n",
        "if LR_UPDATE_INTERVAL_IN_ITERATIONS == None: LR_UPDATE_INTERVAL_IN_ITERATIONS = len(loaders['train'])\n",
        "MODEL_SAVE_INTERVAL_IN_ITERATIONS = MODEL_SAVE_INTERVAL_IN_EPOCHS * len(loaders['train'])\n",
        "\n",
        "# Show data in data loaders\n",
        "print('Trainining samples:')\n",
        "show_batch(loaders['train'])\n",
        "\n",
        "print('Validation samples:')\n",
        "show_batch(loaders['validation'])\n",
        "\n",
        "print('Testing samples:')\n",
        "show_batch(loaders['test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQPr0NLgmJ5p"
      },
      "source": [
        "class Trainer:\n",
        "    \"\"\"\n",
        "    Wrapper object for handling training and evaluation\n",
        "    \"\"\"\n",
        "    def __init__(self, loaders, batch_size, learning_rate, lr_decay, device, multi_gpu):\n",
        "        self.tb = SummaryWriter(comment=TB_COMMENT, log_dir=TB_RUN_DIR)\n",
        "        self.device = device\n",
        "        self.multi_gpu = multi_gpu\n",
        "        self.all_preds = []\n",
        "        self.all_labels = []\n",
        "        self.incorrect_samples = []\n",
        "        self.incorrect_samples_targets = []\n",
        "\n",
        "        self.loaders = loaders\n",
        "        img_shape = self.loaders['train'].dataset[0][0].numpy().shape\n",
        "        \n",
        "        self.net = torchvision.models.resnet50(pretrained=False) # Network model\n",
        "        self.net = self.net.cuda()\n",
        "        \n",
        "        if self.multi_gpu:\n",
        "            self.net = nn.DataParallel(self.net)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.net.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=lr_decay)\n",
        "        print(10*'#', 'PyTorch Model built'.upper(), 10*'#')\n",
        "        print('No. of params:', sum([np.prod(p.size()) for p in self.net.parameters()]))\n",
        "        print(TB_COMMENT)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return repr(self.net)\n",
        "\n",
        "    def run(self, epochs, classes):\n",
        "        print(8*'#', 'Run started'.upper(), 8*'#')\n",
        "        eye = torch.eye(len(classes)).to(self.device)\n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            for phase in ['train', 'validation']:\n",
        "                if phase == 'train':\n",
        "                    self.net.train()\n",
        "                else:\n",
        "                    self.net.eval()\n",
        "\n",
        "                t0 = time()\n",
        "                running_loss = 0.0\n",
        "                running_margin_loss = 0.0\n",
        "                running_reconstruction_loss = 0.0\n",
        "                correct = 0; total = 0\n",
        "                batch_len = len(self.loaders['train'])\n",
        "                for i, (images, labels) in enumerate(self.loaders[phase]):\n",
        "                    n_iter = ((epoch-1) * batch_len) + i\n",
        "                    t1 = time()\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "                    preds = self.net(images) # reconstructions[ BATCH_SIZE, CHANNEL_NO, IMG_DIM, IMG_DIM]\n",
        "                    loss = F.cross_entropy(preds, labels) # Loss function\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        self.optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()\n",
        "\n",
        "                    total += labels.size(0)\n",
        "                    correct += get_num_correct(preds, labels)\n",
        "                    accuracy = float(correct) / float(total)\n",
        "\n",
        "                    if phase == 'train' and (n_iter % LOG_INTERVAL) == 0:\n",
        "                        print('Epoch: {:02d}  Batch {:04d}/{:04d}  Loss: {:.5f},  Accuracy: {:.5f}  Time: {:.3f}s'.format(epoch, i+1, batch_len, running_loss/(i+1), accuracy, time()-t1))\n",
        "\n",
        "                    if phase == 'train' and (n_iter % LR_UPDATE_INTERVAL_IN_ITERATIONS) == 0 and (n_iter != 0):\n",
        "                        self.scheduler.step()\n",
        "\n",
        "                    if phase == 'train' and (n_iter % MODEL_SAVE_INTERVAL_IN_ITERATIONS) == 0 and (n_iter != 0):\n",
        "                        torch.save(self.net.state_dict(), os.path.join(MODEL_DIR, str(n_iter)+'.pth.tar'))\n",
        "                    \n",
        "\n",
        "                print('{} \\tEpoch: {:02d}  Loss: {:.5f}  Accuracy: {:.5f}  Time: {:.3f}s'.format(phase.upper(), epoch, running_loss/(i+1), accuracy, time()-t0))\n",
        "                n_iter = epoch * batch_len\n",
        "                self.tb.add_scalar(f'{phase}/loss', running_loss/(i+1), n_iter)\n",
        "                self.tb.add_scalar(f'{phase}/accuracy', accuracy, n_iter)\n",
        "            \n",
        "        self.tb.close()\n",
        "            \n",
        "        now = str(datetime.now()).replace(\" \", \"-\")\n",
        "        error_rate = round((1-accuracy)*100, 2)\n",
        "        torch.save(self.net.state_dict(), os.path.join(MODEL_DIR, 'model.pth.tar'))\n",
        "\n",
        "    \n",
        "    def test(self, show_per_class_accuracy=False):\n",
        "        self.net.eval()\n",
        "        eye = torch.eye(len(classes)).to(self.device)\n",
        "        t0 = time()\n",
        "        running_loss = 0.0\n",
        "        running_margin_loss = 0.0\n",
        "        running_reconstruction_loss = 0.0\n",
        "        correct = 0; total = 0\n",
        "        batch_len = len(self.loaders['test'])\n",
        "        for i, (images, labels) in enumerate(self.loaders['test']):\n",
        "            t1 = time()\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            preds = self.net(images) # reconstructions[ BATCH_SIZE, CHANNEL_NO, IMG_DIM, IMG_DIM]\n",
        "            loss = F.cross_entropy(preds, labels) # Loss function\n",
        "\n",
        "            incorrect_idxes = torch.nonzero((preds.argmax(dim=1).eq(labels)==False))\n",
        "\n",
        "            for incorrect_idx in incorrect_idxes:\n",
        "                idx = incorrect_idx.item()\n",
        "                self.incorrect_samples.append(images[idx])\n",
        "                self.incorrect_samples_targets.append(labels[idx].item())\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += get_num_correct(preds, labels)\n",
        "            accuracy = float(correct) / float(total)\n",
        "            self.all_labels = np.append(self.all_labels, labels.cpu().numpy())\n",
        "            self.all_preds = np.append(self.all_preds, preds.argmax(dim=1).cpu().numpy())\n",
        "        \n",
        "        print('{} \\tLoss: {:.5f}  M_Loss: {:.5f} R_loss: {:.5f}  Accuracy: {:.5f}  Time: {:.3f}s'.format(\n",
        "            'TEST', \n",
        "            running_loss/(i+1), \n",
        "            running_margin_loss/(i+1), \n",
        "            running_reconstruction_loss/(i+1), \n",
        "            accuracy, \n",
        "            time()-t0))\n",
        "            \n",
        "        now = str(datetime.now()).replace(\" \", \"-\")\n",
        "        error_rate = round((1-accuracy)*100, 2)\n",
        "\n",
        "        if show_per_class_accuracy:\n",
        "            class_correct = list(0. for _ in classes)\n",
        "            class_total = list(0. for _ in classes)\n",
        "            for images, labels in self.loaders['test']:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                preds = self.net(images)\n",
        "                preds = preds.argmax(dim=1)\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i]\n",
        "                    if labels[i] == preds[i]:\n",
        "                        class_correct[label] += 1\n",
        "                    class_total[label] += 1\n",
        "                    \n",
        "            print('\\nPer class accuracy on TEST set:')\n",
        "            for i in range(len(classes)):\n",
        "                print('Accuracy of {} ({}) : {:.2f}%     ({:5d}/{:5d})'.format(classes[i], i, 100 * class_correct[i] / class_total[i], int(class_correct[i]), int(class_total[i])))\n",
        "\n",
        "    def show_incorrect_prediction(self):\n",
        "        print('\\nIncorrect samples\\' corrrect labels: ', self.incorrect_samples_targets)\n",
        "        print('Incorrectly predicted samples:')\n",
        "        fig, ax = plt.subplots(figsize=(25, 25))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        img_grid = torchvision.utils.make_grid(self.incorrect_samples, nrow=10, normalize=True)\n",
        "        _ = ax.imshow(make_grid(img_grid.cpu().detach().permute(1, 2, 0)))\n",
        "\n",
        "    def show_classification_report(self, target_names=classes):\n",
        "        print(classification_report(self.all_labels, self.all_preds, target_names=target_names))\n",
        "\n",
        "    def show_confusion_matrix(self, xticklabels=classes, yticklabels=classes):\n",
        "        confusion_matrix_test = confusion_matrix(self.all_labels, self.all_preds, labels = None, sample_weight = None, normalize = None)\n",
        "        heatmap_test = sn.heatmap(confusion_matrix_test, annot=True)\n",
        "        _ = heatmap_test.set(xlabel='Predicted label', ylabel='Actual label', xticklabels=xticklabels, yticklabels=yticklabels)\n",
        "    \n",
        "    def saveData(self, G_DRIVE_DIR):\n",
        "        try:\n",
        "            if not os.path.exists(G_DRIVE_DIR):\n",
        "                os.mkdir(G_DRIVE_DIR)\n",
        "        except:\n",
        "            print('ERROR: G_DRIVE_DIR dir creation error')\n",
        "\n",
        "        try:\n",
        "            dest = shutil.move( MODEL_DIR, os.path.join(G_DRIVE_DIR, 'models'))\n",
        "            print(\"Transfered to: \", dest)\n",
        "        except:\n",
        "            print('ERROR: G_DRIVE_DIR model transfer error')\n",
        "\n",
        "        try:\n",
        "            dest = shutil.move( TB_RUN_DIR, os.path.join(G_DRIVE_DIR, 'runs'))\n",
        "            print(\"Transfered to: \", dest)\n",
        "        except:\n",
        "             print('ERROR: G_DRIVE_DIR runs transfer error')\n",
        "\n",
        "    def load(self, load_path):\n",
        "        if load_path != None:\n",
        "            try:\n",
        "                self.net.load_state_dict(torch.load(load_path))\n",
        "                _ = self.net.eval()\n",
        "                print('Model state loaded')\n",
        "            except Exception as e: \n",
        "                print('ERROR: Model state load error: ', e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzWB09-FnBZF"
      },
      "source": [
        "if os.path.exists(TB_RUN_DIR):\n",
        "    %tensorboard --logdir='/content/logs/runs'\n",
        "else:\n",
        "    %tensorboard --logdir=G_DRIVE_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEhNXZrinIOP"
      },
      "source": [
        "# Train Model\n",
        "\n",
        "net_trainer = Trainer(loaders, BATCH_SIZE, LEARNING_RATE, LR_DECAY, device=DEVICE, multi_gpu=MULTI_GPU)\n",
        "# net_trainer.load(load_path = None)\n",
        "net_trainer.run(EPOCHS, classes=classes)\n",
        "# net_trainer.saveData(G_DRIVE_DIR)\n",
        "net_trainer.test(show_per_class_accuracy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrn82NvIku4k"
      },
      "source": [
        "net_trainer.show_classification_report()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZkRocpjWFC"
      },
      "source": [
        "net_trainer.show_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh2G0Z-Fom6c"
      },
      "source": [
        "auc = roc_auc_score(net_trainer.all_labels, net_trainer.all_preds)\n",
        "print('ROC AUC Score: {:.3f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNiGmJmSjnwS"
      },
      "source": [
        "net_trainer.show_incorrect_prediction()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}